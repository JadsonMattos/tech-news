# Boas-vindas ao reposit√≥rio do Tech News

<details>
  <summary><strong>üë®‚Äçüíª O que dever√° ser desenvolvido</strong></summary><br />

  Voc√™ far√° um projeto que tem como principal objetivo fazer consultas em not√≠cias sobre tecnologia.

  As not√≠cias podem ser obtidas atrav√©s da raspagem do [_blog da Trybe_](https://blog.betrybe.com).

  <strong>üöµ Habilidades a serem trabalhadas:</strong>
  <ul>
    <li>Utilizar o terminal interativo do Python</li>
    <li>Escrever seus pr√≥prios m√≥dulos e import√°-los em outros c√≥digos</li>
    <li>Aplicar t√©cnicas de raspagem de dados</li>
    <li>Extrair dados de conte√∫do HTML</li>
    <li>Armazenar os dados obtidos em um banco de dados</li>
  </ul>

</details>

# Orienta√ß√µes

<details>
  <summary><strong>‚ö† Antes de come√ßar a desenvolver</strong></summary><br />

  1. Crie o ambiente virtual para o projeto

* `python3 -m venv .venv && source .venv/bin/activate`
  
  3. Instale as depend√™ncias

* `python3 -m pip install -r dev-requirements.txt`
  
</details>

<details>
  <summary><strong>üèïÔ∏è Ambiente Virtual</strong></summary><br />
  O Python oferece um recurso chamado de ambiente virtual, onde permite sua m√°quina rodar sem conflitos, diferentes tipos de projetos com diferentes vers√µes de bibliotecas.

  1. **criar o ambiente virtual**

  ```bash
python3 -m venv .venv
  ```

  2. **ativar o ambiente virtual**

  ```bash
source .venv/bin/activate
  ```

  3. **instalar as depend√™ncias no ambiente virtual**

  ```bash
python3 -m pip install -r dev-requirements.txt
  ```

  Com o seu ambiente virtual ativo, as depend√™ncias ser√£o instaladas neste ambiente.
  Quando precisar desativar o ambiente virtual, execute o comando "deactivate". Lembre-se de ativar novamente quando voltar a trabalhar no projeto.

  O arquivo `dev-requirements.txt` cont√©m todas as depend√™ncias que ser√£o utilizadas no projeto, ele est√° agindo como se fosse um `package.json` de um projeto `Node.js`.
</details>

<details>
  <summary><strong>üèÉüèæ Executando o Projeto</strong></summary>
  As not√≠cias a serem raspadas estar√£o dispon√≠veis no _Blog da Trybe_: https://blog.betrybe.com.
  Essas not√≠cias devem ser salvas no banco de dados utilizando as fun√ß√µes python que j√° v√™m prontas no m√≥dulo `database.py`

  <strong>MongoDB</strong>

  Para a realiza√ß√£o deste projeto, utilizaremos um banco de dados chamado `tech_news`.
  As not√≠cias ser√£o armazenadas em uma cole√ß√£o chamada `news`.
  J√° existem algumas fun√ß√µes prontas no arquivo `tech_news/database.py` que te auxiliar√£o no desenvolvimento.
  N√£o altere as fun√ß√µes deste arquivo; mudan√ßas nele n√£o ser√£o executadas no avaliador autom√°tico.

  Rodar MongoDB via Docker:
  <code>docker-compose up -d mongodb</code> no terminal.
  Para mais detalhes acerca do mongo com o docker, olhe o arquivo `docker-compose.yml`

  Caso queira instalar e rodar o servidor MongoDB nativo na m√°quina, siga as instru√ß√µes no tutorial oficial:

  Ubuntu: <https://docs.mongodb.com/manual/tutorial/install-mongodb-on-ubuntu/>
  MacOS:  <https://docs.mongodb.com/guides/server/install/>
  
  Com o banco de dados rodando, o nosso m√≥dulo conseguir√° acess√°-lo sem problemas. Importe o m√≥dulo `tech_news/database.py` e chame as fun√ß√µes contidas nele.
  Lembre-se de que o mongoDB utilizar√° por padr√£o a porta 27017. Se j√° houver outro servi√ßo utilizando esta porta, considere desativ√°-lo.

</details>

# Requisitos obrigat√≥rios

Ao longo do projeto, voc√™ estar√° construindo um sistema de busca de not√≠cias sobre tecnologia. Para isso, voc√™ precisar√° fazer a raspagem de dados do blog da Trybe, e armazenar estas not√≠cias em um banco de dados MongoDB.

Preparamos uma interface em linha de comando (CLI) para voc√™ usar o seu sistema de busca. Esta CLI j√° est√° pronta, e voc√™ n√£o precisar√° alter√°-la. Para us√°-la, basta instalar as depend√™ncias e executar o seguinte comando no terminal:

```bash
tech-news-analyzer
```

Quando os requisitos estiverem completos, voc√™ poder√° usar a CLI para atualizar o banco de not√≠cias, e fazer buscas por not√≠cias! üéâ

## 1 - Crie a fun√ß√£o `fetch`

local: `tech_news/scraper.py`

Antes de fazer scrape, precisamos de uma p√°gina! Esta fun√ß√£o ser√° respons√°vel por fazer a requisi√ß√£o HTTP ao site e obter o conte√∫do HTML.
Alguns cuidados dever√£o ser tomados: como a nossa fun√ß√£o poder√° ser utilizada v√°rias vezes em sucess√£o, na nossa implementa√ß√£o devemos nos assegurar que um [Rate Limit](https://app.betrybe.com/learn/course/5e938f69-6e32-43b3-9685-c936530fd326/module/290e715d-73e3-4b2d-a3c7-4fe113474070/section/7e82ac53-a588-412b-95a5-19727d70ed3a/day/9488d307-4a72-4c82-887f-d860ad20a1af/lesson/d1b4c16d-1cef-4fdd-a7e6-a45770074077) ser√° respeitado.

* A fun√ß√£o deve receber uma URL
* A fun√ß√£o deve fazer uma requisi√ß√£o HTTP `get` para esta URL utilizando a fun√ß√£o `requests.get`
* A fun√ß√£o deve retornar o conte√∫do HTML da resposta.
* A fun√ß√£o deve respeitar um Rate Limit de 1 requisi√ß√£o por segundo; Ou seja, caso chamada m√∫ltiplas vezes, ela deve aguardar 1 segundo entre cada requisi√ß√£o que fizer.
**Dica:** Uma forma simples de garantir que cada requisi√ß√£o seja feita com um intervalo m√≠nimo de um segundo √© utilizar `time.sleep(1)` antes de cada requisi√ß√£o. (Existem outras formas mais eficientes.)
* Caso a requisi√ß√£o seja bem sucedida com `Status Code 200: OK`, deve ser retornado seu conte√∫do de texto;
* Caso a resposta tenha o c√≥digo de status diferente de `200`, deve-se retornar `None`;
* Caso a requisi√ß√£o n√£o receba resposta em at√© 3 segundos, ela deve ser abandonada (este caso √© conhecido como "Timeout") e a fun√ß√£o deve retornar None.

üìå Voc√™ vai precisar definir o _header_ `user-agent` para que a raspagem do blog da Trybe funcione corretamente. Para isso, preencha com o valor `"Fake user-agent"` conforme exemplo abaixo:

```python
{ "user-agent": "Fake user-agent" }
```

## 2 - Crie a fun√ß√£o `scrape_updates`

local: `tech_news/scraper.py`

Para conseguirmos fazer o scrape da p√°gina de uma not√≠cia, primeiro precisamos de links para v√°rias p√°ginas de not√≠cias. Estes links est√£o contidos na p√°gina inicial do blog da Trybe (<https://blog.betrybe.com>).

Esta fun√ß√£o far√° o scrape da p√°gina Novidades para obter as URLs das p√°ginas de not√≠cias. Vamos utilizar as ferramentas que aprendemos no curso, como a biblioteca Parsel, para obter os dados que queremos de cada p√°gina.

* A fun√ß√£o deve receber uma string com o conte√∫do HTML da p√°gina inicial do blog
* A fun√ß√£o deve fazer o scrape do conte√∫do recebido para obter uma lista contendo as URLs das not√≠cias listadas.
  * ‚ö†Ô∏è _Aten√ß√£o:_ **N√ÉO** inclua a not√≠cia em destaque da primeira p√°gina, apenas as not√≠cias dos cards.
* A fun√ß√£o deve retornar esta lista.
* Caso n√£o encontre nenhuma URL de not√≠cia, a fun√ß√£o deve retornar uma lista vazia.

## 3 - Crie a fun√ß√£o `scrape_next_page_link`

local: `tech_news/scraper.py`

Para buscar mais not√≠cias, precisaremos fazer a pagina√ß√£o, e para isto, vamos precisar do link da pr√≥xima p√°gina. Esta fun√ß√£o ser√° respons√°vel por fazer o scrape deste link.

* A fun√ß√£o deve receber como par√¢metro uma `string` contendo o conte√∫do HTML da p√°gina de novidades (<https://blog.betrybe.com>)
* A fun√ß√£o deve fazer o scrape deste HTML para obter a URL da pr√≥xima p√°gina.
* A fun√ß√£o deve retornar a URL obtida.
* Caso n√£o encontre o link da pr√≥xima p√°gina, a fun√ß√£o deve retornar `None`

## 4 - Crie a fun√ß√£o `scrape_news`

local: `tech_news/scraper.py`

Agora que sabemos pegar p√°ginas HTML, e descobrir o link de not√≠cias, √© hora de fazer o scrape dos dados que procuramos!

* A fun√ß√£o deve receber como par√¢metro o conte√∫do HTML da p√°gina de uma √∫nica not√≠cia
* A fun√ß√£o deve, no conte√∫do recebido, buscar as informa√ß√µes das not√≠cias para preencher um dicion√°rio com os seguintes atributos:
  * `url` - link para acesso da not√≠cia.
  * `title` - t√≠tulo da not√≠cia.
  * `timestamp` - data da not√≠cia, no formato `dd/mm/AAAA`.
  * `writer` - nome da pessoa autora da not√≠cia.
  * `reading_time` - n√∫mero de minutos necess√°rios para leitura.
  * `summary` - o primeiro par√°grafo da not√≠cia.
  * `category` - categoria da not√≠cia.

* Exemplo de um retorno da fun√ß√£o com uma not√≠cia fict√≠cia:

```json
{
  "url": "https://blog.betrybe.com/novidades/noticia-bacana",
  "title": "Not√≠cia bacana",
  "timestamp": "04/04/2021",
  "writer": "Eu",
  "reading_time": 4,
  "summary": "Algo muito bacana aconteceu",
  "category": "Ferramentas",
}
  ```

üìå Muita aten√ß√£o aos tipos dos campos, por exemplo, `category` √© uma string enquanto `reading_time` √© num√©rico.

üìå Os textos coletados em `title` e `summary` podem conter alguns caracteres vazios ao final. O teste espera que esses caracteres sejam removidos.

üìå **√â bom saber que** ao fazer scraping na vida real, voc√™ est√° sempre "ref√©m" de quem construiu o site. Por exemplo, pode ser que nem toda not√≠cia tenha **exatamente** o mesmo HTML/CSS e voc√™ precise de criatividade para contornar isso.

üìå Caso uma tag possua outras tags aninhadas, voc√™ pode usar o seletor ```*``` para obter informa√ß√µes da tag ancestral e tamb√©m de suas tags descendentes.

---

## 5 - Crie a fun√ß√£o `get_tech_news` para obter as not√≠cias

local: `tech_news/scraper.py`

Agora, chegou a hora de aplicar todas as fun√ß√µes que voc√™ acabou de fazer. Com estas ferramentas prontas, podemos fazer nosso scraper mais robusto com a pagina√ß√£o.

* A fun√ß√£o deve receber como par√¢metro um n√∫mero inteiro `n` e buscar as √∫ltimas `n` not√≠cias do site.
* Utilize as fun√ß√µes `fetch`, `scrape_updates`, `scrape_next_page_link` e `scrape_news` para buscar as not√≠cias e processar seu conte√∫do.
* As not√≠cias buscadas devem ser inseridas no MongoDB; Para acessar o banco de dados, importe e utilize as fun√ß√µes que j√° temos prontas em `tech_news/database.py`
* Ap√≥s inserir as not√≠cias no banco, a fun√ß√£o deve retornar estas mesmas not√≠cias.

üìå De aqui em diante, usaremos o MongoDB.

Rodar MongoDB via Docker: `docker-compose up -d mongodb` no terminal.
Para mais detalhes acerca do mongo com o docker, olhe o arquivo `docker-compose.yml`

Caso queira instalar e rodar o servidor MongoDB nativo na m√°quina, siga as instru√ß√µes no tutorial oficial:
Ubuntu: <https://docs.mongodb.com/manual/tutorial/install-mongodb-on-ubuntu/>  
MacOS:  <https://docs.mongodb.com/guides/server/install/>
  
Com o banco de dados rodando, o nosso m√≥dulo conseguir√° acess√°-lo sem problemas. Importe o m√≥dulo `tech_news/database.py` e chame as fun√ß√µes contidas nele.
N√£o altere as fun√ß√µes deste m√≥dulo; elas ser√£o utilizadas nos testes.

## 6 - Teste a classe `ReadingPlanService`

local: `tests/reading_plan/test_reading_plan.py`

Agora que temos meios de popular nosso banco de dados com not√≠cias, podemos fazer uso de uma funcionalidade implementada por outro time!

O servi√ßo de **planejamento de leituras**, implementado no arquivo `tech_news/analyzer/reading_plan.py`, coleta as not√≠cias do banco de dados e as divide em 2 agrupamentos:

1. `readable`: not√≠cias que podem ser lidas em at√© `X` minutos
2. `unreadable`: not√≠cias que **n√£o** podem ser lidas em at√© `X` minutos

Al√©m disso, as not√≠cias `readable` s√£o organizadas em sub-grupos cuja soma dos tempos de leitura seja menor que `X`. Assim, a pessoa leitora pode ler mais do que 1 not√≠cia sem ultrapassar o tempo dispon√≠vel!

O valor de `X`, que √© o tempo de leitura que uma pessoa tem dispon√≠vel, √© passado por par√¢metro no m√©todo `group_news_for_available_time`, que √© um **m√©todo de classe**.

üìå Voc√™ deve implementar o teste `test_reading_plan_group_news` para garantir o funcionamento correto deste m√©todo que est√° explicado abaixo. Ah, n√£o se preocupe em testar a chamada dos outros m√©todos da classe!

üìå O m√©todo `group_news_for_available_time` utiliza a fun√ß√£o `find_news` do m√≥dulo `tech_news.database` para coletar as not√≠cias no banco de dados. Pode ser importante mockar essa fun√ß√£o para que o resultado do teste n√£o dependa do banco de dados.

## 7 - Crie a fun√ß√£o `search_by_title`

local: `tech_news/analyzer/search_engine.py`

Al√©m de testar funcionalidades que acessam o banco, podemos fazer as nossas pr√≥prias funcionalidades! Esta fun√ß√£o ir√° fazer buscas por t√≠tulo.

* A fun√ß√£o deve receber uma string com um t√≠tulo de not√≠cia
* A fun√ß√£o deve buscar as not√≠cias do banco de dados por t√≠tulo
* A fun√ß√£o deve retornar uma lista de tuplas com as not√≠cias encontradas nesta busca.
Exemplo:

```python
[
  ("T√≠tulo1_aqui", "url1_aqui"),
  ("T√≠tulo2_aqui", "url2_aqui"),
  ("T√≠tulo3_aqui", "url3_aqui"),
]
```

* A busca deve ser _case insensitive_

* Caso nenhuma not√≠cia seja encontrada, deve-se retornar uma lista vazia.

üìå Lembre-se; para acesso ao banco de dados importe `db` definido no m√≥dulo `tech_news/database.py`.

## 8 - Crie a fun√ß√£o `search_by_date`

local: `tech_news/analyzer/search_engine.py`

Esta fun√ß√£o ir√° buscar as not√≠cias do banco de dados por data.

* A fun√ß√£o deve receber como par√¢metro uma data no formato ISO `AAAA-mm-dd`
* A fun√ß√£o deve buscar as not√≠cias do banco de dados por data.
* A fun√ß√£o deve ter retorno no mesmo formato do requisito anterior.
* Caso a data seja inv√°lida, ou esteja em outro formato, uma exce√ß√£o `ValueError` deve ser lan√ßada com a mensagem `Data inv√°lida`.
* Caso nenhuma not√≠cia seja encontrada, deve-se retornar uma lista vazia.

üìå Lembre-se: A fun√ß√£o recebe uma data no formato ISO `AAAA-mm-dd`, mas no banco a data est√° salva no formato `dd/mm/AAAA`. **Dica:** Lembrem-se de como trabalhamos com datas nos projetos anteriores.

## 9 - Crie a fun√ß√£o `search_by_category`

local: `tech_news/analyzer/search_engine.py`

Esta fun√ß√£o ir√° buscar as not√≠cias por categoria.

* A fun√ß√£o deve receber como par√¢metro o nome da categoria completo.
* A fun√ß√£o deve buscar as not√≠cias do banco de dados por categoria.
* A fun√ß√£o deve ter retorno no mesmo formato do requisito anterior.
* Caso nenhuma not√≠cia seja encontrada, deve-se retornar uma lista vazia.
* A busca deve ser _case insensitive_

# Requisitos b√¥nus

## 10 - Crie a fun√ß√£o `top_5_categories`

local: `tech_news/analyzer/ratings.py`

Esta fun√ß√£o ir√° listar as cinco categorias com maior ocorr√™ncia no banco de dados.

* A fun√ß√£o deve buscar as categorias do banco de dados e calcular a sua "popularidade" com base no n√∫mero de ocorr√™ncias;
* As top 5 categorias da an√°lise devem ser retornadas em uma lista no formato `["category1", "category2"]`;
* A ordem das categorias retornadas deve ser da mais popular para a menos popular, ou seja, categorias que est√£o em mais not√≠cias primeiro;
* Em caso de empate, o desempate deve ser por ordem alfab√©tica de categoria.
* Caso haja menos de cinco categorias, no banco de dados, deve-se retornar todas as categorias existentes;
* Caso n√£o haja categorias dispon√≠veis, deve-se retornar uma lista vazia.

---
